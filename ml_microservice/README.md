# AI Marketer Pro ML Microservice

Microservice machine learning cho d·ª± ƒëo√°n engagement, ph√¢n t√≠ch sentiment, t·ªëi ∆∞u content v√† ph√°t hi·ªán b·∫•t th∆∞·ªùng trong AI Marketer Pro.

## üìã M·ª•c l·ª•c

- [T·ªïng quan](#t·ªïng-quan)
- [Flow ho·∫°t ƒë·ªông](#flow-ho·∫°t-ƒë·ªông)
- [Ki·∫øn tr√∫c](#ki·∫øn-tr√∫c)
- [Training Pipeline](#training-pipeline)
- [API Endpoints](#api-endpoints)
- [T√≠ch h·ª£p Laravel](#t√≠ch-h·ª£p-laravel)
- [L·ªánh ch·∫°y](#l·ªánh-ch·∫°y)

## üìñ T·ªïng quan

Microservice bao g·ªìm 4 m√¥ h√¨nh ch√≠nh:

1. **üéØ Engagement Prediction** - XGBoost: D·ª± ƒëo√°n m·ª©c ƒë·ªô t∆∞∆°ng t√°c b√†i post
2. **üòä Sentiment Analysis** - BERT: Ph√¢n t√≠ch c·∫£m x√∫c & √Ω ƒë·ªãnh b√¨nh lu·∫≠n
3. **‚ú® Content Optimization** - Sentence BERT: T·ªëi ∆∞u n·ªôi dung ƒë·ªÉ tƒÉng engagement
4. **üìä Anomaly Detection** - Statistical ML: Ph√°t hi·ªán b·∫•t th∆∞·ªùng trong engagement

## üîÑ Flow ho·∫°t ƒë·ªông

### Training Phase
```
Data Collection ‚Üí Preprocessing ‚Üí Model Training ‚Üí Model Saving ‚Üí Deployment
```

**Detail t·ª´ng phase:**

1. **Data Collection:**
   - Engagement data: reactions, comments, shares, post content, timestamps
   - Sentiment data: comment texts v·ªõi labels positive/neutral/negative
   - Content templates: high-performing posts ƒë·ªÉ t·ªëi ∆∞u
   - Time-series data: engagement history cho anomaly detection

2. **Preprocessing:**
   - Text cleaning & tokenization
   - Feature engineering (content_length, hour, weekday)
   - Label encoding cho predictors
   - Embedding generation cho semantic analysis

3. **Model Training:**
   - XGBoost cho regression problems (~1000 samples, CV 5-fold)
   - BERT fine-tuning tr√™n labeled sentiment data
   - Isolation Forest ho·∫∑c threshold-based cho anomaly detection
   - Sentence-BERT training cho content similarity

4. **Model Saving:**
   - XGBoost: joblib.dump(model, 'engagement.joblib')
   - BERT: model.save_pretrained('sentiment_model/')
   - Anomaly: kh√¥ng c·∫ßn save (statistical methods)

### Prediction Phase
```
Laravel Request ‚Üí ML API Call ‚Üí Model Load ‚Üí Feature Processing ‚Üí Prediction ‚Üí Response ‚Üí UI Display
```

**Chi ti·∫øt t·ª´ng b∆∞·ªõc:**

1. **Laravel call ML APIs:**
   ```php
   $response = Http::post('http://localhost:8001/predict-engagement', [
       'content' => $post->message,
       'reacts' => $post->reactions,
       // ...
   ]);
   ```

2. **FastAPI x·ª≠ l√Ω:**
   ```python
   @app.post("/predict-engagement")
   def predict(request: EngagementRequest):
       # Load model on startup
       features = [len(request.content), request.reacts, ...]
       prediction = model.predict([features])[0]
       return EngagementResponse(...)
   ```

3. **UI hi·ªÉn th·ªã k·∫øt qu·∫£:**
   ```
   Laravel Controller ‚Üí pass $ml_insights to Blade view
   ‚Üí Display predictions trong cards v·ªõi colors/icons
   ```

## üèóÔ∏è Ki·∫øn tr√∫c

### FastAPI Structure
```
ml_microservice/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI instance & router include
‚îÇ   ‚îú‚îÄ‚îÄ routers/             # API endpoints (4 files)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic request/response
‚îÇ   ‚îú‚îÄ‚îÄ services/            # ML logic & model loading
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Saved models (.joblib, .pt)
‚îÇ   ‚îî‚îÄ‚îÄ config.py            # MySQL connection config
‚îú‚îÄ‚îÄ train_models.py          # Training pipeline
‚îî‚îÄ‚îÄ requirements.txt         # Dependencies
```

### Laravel Integration
```
Laravel Controller
    ‚Üì
MLService::predictEngagement($data)
    ‚Üì
HTTP POST to FastAPI:8001
    ‚Üì
FastAPI process & return predictions
    ‚Üì
Blade view render results
    ‚Üì
User see AI-powered insights
```

## üéØ API Endpoints

| Endpoint | Method | Description | Input | Output |
|----------|--------|-------------|-------|--------|
| `/predict-engagement` | POST | D·ª± ƒëo√°n engagement | `content`, `reacts`, `shares`, `comments`, `time_posted` | `predicted_engagement`, `growth_rate`, `best_time`, `suggestions` |
| `/predict-sentiment` | POST | Ph√¢n t√≠ch sentiment | `comments[]` | `overall_sentiment`, `intents[]`, `risk_level` |
| `/optimize-content` | POST | T·ªëi ∆∞u content | `content` | `optimized_content`, `improvements{}` |
| `/detect-anomaly` | POST | Ph√°t hi·ªán anomaly | `engagement_data[]`, `timestamps[]` | `is_anomaly`, `anomaly_score`, `message` |

## üöÄ Training Pipeline

### 1. Prepare Data

**Real Data from Campaign Analytics Table:**
```python
# Query real data from campaign_analytics table
query = """
    SELECT
        ca.reactions_total,
        ca.comments,
        ca.shares,
        ca.post_message,
        ca.post_created_time,
        ca.status_type
    FROM campaign_analytics ca
    WHERE (ca.reactions_total + ca.comments + ca.shares) >= 10
    AND ca.post_created_time IS NOT NULL
"""

# Features extracted:
features = [
    'reacts', 'comments', 'shares',        # Basic engagement
    'content_length',                      # Text analysis
    'hour', 'weekday', 'is_weekend',       # Time-based features
    'is_photo', 'is_video', 'is_link'      # Content type features
]

# Target: Weighted engagement score
target = (
    reacts * 1.5 +      # Reactions weight
    comments * 3 +      # Comments high engagement value
    shares * 5          # Shares viral indicator
)
```

**Fallback: Synthetic Data (if insufficient real data):**
```python
# Only used if database has < 100 training samples
np.random.seed(42)
n_samples = 1000

features = {
    'content_length': np.random.randint(50, 500, n_samples),
    'reacts': np.random.randint(0, 1000, n_samples),
    'shares': np.random.randint(0, 100, n_samples),
    'comments': np.random.randint(0, 50, n_samples),
    'hour': np.random.randint(0, 24, n_samples),
    # ... more realistic features
}
```

**Sentiment Model Data:**
```python
# Real Facebook comments with sentiment labels
training_data = [
    {"text": "Great product! Love it", "label": "positive"},
    {"text": "This sucks, terrible quality", "label": "negative"},
    # ... thousands of examples
]
```

**Optimization Model Data:**
```python
# High-performing post templates
successful_posts = [
    "Amazing deal! Buy now and save 50% #Deal",
    "What a fantastic experience! Loved every moment #Happy",
    # ...
]

# Embedding similar posts together
embeddings = SentenceTransformer('bert-base-nli-mean-tokens')
sentence_embeddings = embeddings.encode(successful_posts)
```

### 2. Verify Database Connection (Important!)

Before training, ensure database connection works:

```bash
cd ml_microservice
python test_db_connection.py
```

**Expected output:**
```
üîç Testing ML Microservice Database Connection
‚úÖ Connected to database: ai_marketer_pro
‚úÖ Table 'campaign_analytics' exists with 20 columns:
  - id: int(11)
  - campaign_id: int(11) unsigned
  - ad_schedule_id: int(11) unsigned
  - facebook_post_id: varchar(255)
  - reactions_total: int(11)
  - comments: int(11)
  - shares: int(11)
  - post_message: text
  - post_created_time: timestamp
  - status_type: varchar(255)
  (and more...)
‚úÖ Total records in campaign_analytics: 1250

üìä Sample Data Statistics:
   - Total qualifying records: 850
   - Average reactions: 125.6
   - Average comments: 23.4
   - Average shares: 8.9

‚úÖ All database checks passed!
You can now run: python train_models.py
```

### 3. Train Models with Real Data

```bash
python train_models.py

**What happens in training:**

1. **XGBoost Training:**
   ```python
   from xgboost import XGBRegressor

   model = XGBRegressor(
       objective='reg:squarederror',
       n_estimators=100,
       learning_rate=0.1,
       max_depth=6,
       random_state=42
   )
   model.fit(X_train, y_train)
   joblib.dump(model, 'app/models/engagement.joblib')
   ```

2. **BERT Training:**
   ```python
   from transformers import BertForSequenceClassification, TrainingArguments

   model = BertForSequenceClassification.from_pretrained(
       'nlptown/bert-base-multilingual-uncased-sentiment',
       num_labels=3  # positive, neutral, negative
   )

   training_args = TrainingArguments(
       output_dir='./results',
       num_train_epochs=3,
       per_device_train_batch_size=16,
   )

   trainer = Trainer(
       model=model,
       args=training_args,
       train_dataset=train_dataset,
   )
   trainer.train()
   model.save_pretrained('./app/models/sentiment')
   ```

3. **Sentence BERT (optional for advanced optimization):**
   ```python
   model = SentenceTransformer('all-MiniLM-L6-v2')
   model.fit(samples, warmup_steps=100, epochs=1)
   model.save('./app/models/optimizer')
   ```

### 3. Model Loading & Prediction

**At Startup:**
```python
# engagement_service.py
model = None
def load_model():
    global model
    try:
        model = joblib.load('app/models/engagement.joblib')
    except:
        pass  # stub mode
```

**Prediction:**
```python
def predict_engagement(request):
    if model is None:
        return STUB_RESPONSE

    # Feature engineering
    content_length = len(request.content)
    reacts = request.reacts
    shares = request.shares
    comments = request.comments
    time = datetime.fromisoformat(request.time_posted)
    hour = time.hour
    weekday = time.weekday()

    features = [content_length, reacts, shares, comments, hour, weekday]

    prediction = model.predict([features])[0]
    return EngagementResponse(...)
```

## üîó T√≠ch h·ª£p Laravel

### MLService trong Laravel
```php
// app/Services/Dashboard/CampaignTracking/MLService.php
public function predictEngagement(array $data) {
    return Http::post('http://localhost:8001/predict-engagement', $data)->json();
}

public function analyzePost($analytics) {
    $results = [
        'engagement_prediction' => $this->predictEngagement([...]),
        'sentiment_analysis' => $this->predictSentiment([...]),
        'content_optimization' => $this->optimizeContent([...]),
    ];
    return $results;
}
```

### Trong Controller
```php
// CampaignTrackingController@show
$mlService = app(MLService::class);
$mlAvailable = $mlService->isServiceAvailable();

foreach($schedules as $schedule) {
    if($schedule->latest_analytics && $mlAvailable) {
        $schedule->ml_insights = $mlService->analyzePost($schedule->latest_analytics);
    }
}

// Pass to view
return view('show', compact('campaign', 'schedules', 'totalStats', 'mlInsights'));
```

### Hi·ªÉn th·ªã trong Blade
```blade
@if(isset($schedule->ml_insights['engagement_prediction']))
    <div class="bg-green-50 p-4 rounded-lg">
        <h5>AI Engagement Prediction:</h5>
        <p>Predicted: {{ number_format($schedule->ml_insights['engagement_prediction']['predicted_engagement']) }}</p>
        @isset($schedule->ml_insights['sentiment_analysis'])
            <p>Sentiment: {{ $schedule->ml_insights['sentiment_analysis']['overall_sentiment'] }}</p>
        @endisset
    </div>
@endif
```

## üèÅ L·ªánh ch·∫°y

### Setup & Training
```bash
# 1. Navigate to microservice directory
cd c:\laragon\www\ai_marketer_pro\ml_microservice

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. (Optional) Train models
python train_models.py

# 4. Start FastAPI server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8001

# API docs available at: http://localhost:8001/docs
```

### Test Individual APIs
```bash
# Engagement prediction
curl -X POST "http://localhost:8001/predict-engagement" \
-H "Content-Type: application/json" \
-d '{
  "content": "Amazing product! Buy now #Deal",
  "reacts": 10, "shares": 5, "comments": 3,
  "time_posted": "2023-10-01T14:30:00"
}'

# Sentiment analysis
curl -X POST "http://localhost:8001/predict-sentiment" \
-H "Content-Type: application/json" \
-d '{"comments": ["Great!", "Love it", "Not bad"]}'

# Content optimization
curl -X POST "http://localhost:8001/optimize-content" \
-H "Content-Type: application/json" \
-d '{"content": "Simple promotion text"}'

# Anomaly detection
curl -X POST "http://localhost:8001/detect-anomaly" \
-H "Content-Type: application/json" \
-d '{"engagement_data": [100,120,110,1500,140],"timestamps": ["2023-10-01","2023-10-02","2023-10-03","2023-10-04","2023-10-05"]}'
```

### Laravel Integration Testing
1. Start ML service tr√™n port 8001
2. Truy c·∫≠p campaign tracking page trong Laravel
3. ML insights s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã t·ª± ƒë·ªông n·∫øu c√≥ data

## üö® Troubleshooting

### ML Service Down
- Service kh√¥ng active ‚Üí display warning message in UI
- API timeout ‚Üí fallback to stub responses
- Log errors trong Laravel logs

### Model Not Trained
- S·ª≠ d·ª•ng dummy responses
- User can retrain v·ªõi `python train_models.py`

### Performance Issues
- Add caching layer (Redis)
- Batch predictions
- Async processing cho heavy requests

## üîÆ Production Deployment

### Docker Image
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Scaling Options
- Kubernetes deployment v·ªõi HPA (horizontal pod autoscaling)
- Load balancer ph√¢n ph·ªëi requests
- Async ML tasks v·ªõi worker queues

### Monitoring
- Prometheus metrics
- Health check endpoints
- Model performance tracking
- Prediction accuracy monitoring

---

**Ready to boost your marketing campaigns with AI insights! üéâ**
